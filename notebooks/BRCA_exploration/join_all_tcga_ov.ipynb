{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This created a full dataframe with each row a slide and all metadata for the TCGA dataset. From here all tasks can be defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "425"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Patient spatus and genomic features.  What Zsofi gave us from TCGA.\n",
    "status = pd.read_csv('../../data/TCGA_metadata/TCGA_OV_HRDstatus.txt', sep='\\t', index_col=0)\n",
    "len(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TCGA-04-1331    1\n",
       "TCGA-29-1702    1\n",
       "TCGA-25-2401    1\n",
       "TCGA-25-2404    1\n",
       "TCGA-25-2408    1\n",
       "               ..\n",
       "TCGA-13-A5FU    1\n",
       "TCGA-20-0987    1\n",
       "TCGA-20-0990    1\n",
       "TCGA-20-0991    1\n",
       "TCGA-WR-A838    1\n",
       "Name: bcr_patient_barcode, Length: 587, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drugs = pd.read_csv(\"/mnt/ncshare/ozkilim/BRCA/data/TCGA_metadata/hnsc_lusc_luad_ov_breast_drugs.txt\", sep='\\t')\n",
    "df_drugs[\"pharmaceutical_therapy_drug_name\"] = df_drugs[\"Drug\"]\n",
    "df_responces = pd.read_csv(\"/mnt/ncshare/ozkilim/BRCA/data/TCGA_metadata/panTCGA_drug_treatment.txt\", sep='\\t') #All TCGA responces\n",
    "df = pd.read_excel(\"/mnt/ncshare/ozkilim/BRCA/data/TCGA_metadata/TCGA-CDR-SupplementalTableS1.xlsx\")\n",
    "df_OV = df[df[\"type\"] == \"OV\"]\n",
    "print(len(df_OV))\n",
    "df_OV[\"bcr_patient_barcode\"].value_counts() # only single patients... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530\n",
      "2515\n"
     ]
    }
   ],
   "source": [
    "merged_ov = pd.merge(df_OV, df_responces, on=\"bcr_patient_barcode\", how=\"inner\")\n",
    "print(len(merged_ov[\"bcr_patient_barcode\"].unique())) #530 unique patients with resonce data... \n",
    "print(len(merged_ov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_merged = pd.merge(merged_ov, df_drugs, on=\"pharmaceutical_therapy_drug_name\", how=\"inner\") #here we loose 7 patients... they dont have drug types?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation to give platina +1 if the patient got at least one platin drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503\n"
     ]
    }
   ],
   "source": [
    "# Define an aggregation dictionary for all columns except 'bcr_patient_barcode'\n",
    "aggregation_functions = {}\n",
    "for column in all_merged.columns:\n",
    "    if column != 'bcr_patient_barcode':\n",
    "        if column == 'platina':  # Assuming 'platina' needs to use 'first'\n",
    "            aggregation_functions[column] = 'max'\n",
    "        else:\n",
    "            aggregation_functions[column] = 'first' # Or other appropriate function\n",
    "\n",
    "# Group by 'bcr_patient_barcode' and aggregate using the defined functions\n",
    "aggregated_patients_df = all_merged.groupby('bcr_patient_barcode', as_index=False).agg(aggregation_functions)\n",
    "# Remove patients who never got any platin based drugs \n",
    "aggregated_patients_df = aggregated_patients_df.loc[aggregated_patients_df['platina'] != 0]\n",
    "# rename patients ids column for merging \n",
    "aggregated_patients_df = aggregated_patients_df.rename(columns={\"bcr_patient_barcode\": \"PatientID\"})\n",
    "\n",
    "aggregated_patients_df = aggregated_patients_df[aggregated_patients_df['DSS'].notna()]\n",
    "\n",
    "print(len(aggregated_patients_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of patients with platinum treatment responce data (DSS) : 503\n",
    "### Number of patients with HRD data : 425\n",
    "### Number of intersecting patients: 366"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366\n"
     ]
    }
   ],
   "source": [
    "all_labels = pd.merge(aggregated_patients_df, status, on=\"PatientID\", how=\"inner\") # find intersection of patients with genomic and platin data ...\n",
    "all_labels = all_labels.drop(columns=[\"Unnamed: 0_x\", \"Unnamed: 0_y\"])\n",
    "print(len(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = list(Path('/tank/WSI_data/Ovarian_WSIs/TCGA-OV').glob('*.svs'))\n",
    "# paths[:5]\n",
    "slide_info = np.array([['-'.join(path.name.split('-')[:3]), path.name.split('.')[0][-3:]] for path in paths])\n",
    "slide_names, slide_types = slide_info[:, 0], slide_info[:, 1]\n",
    "# paths #get path name from these ....\n",
    "slide_names = np.array(['-'.join(path.name.split('-')[:10])[:-4] for path in paths])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make each row a silde ID with the rest of the solumn with the labvels for that patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the dataframe with the slide names corresponding to the status file\n",
    "df = all_labels.copy()\n",
    "\n",
    "df['slide_paths'] = [None] * len(df)\n",
    "df['slide_types'] = [None] * len(df)\n",
    "\n",
    "for ind, row in df.iterrows():\n",
    "    df.loc[ind, 'slide_paths'] = ','.join([str(path).split('/')[-1].replace('.svs', '') for path in paths if row['PatientID'] in str(path)])\n",
    "    df.loc[ind, 'slide_types'] = ','.join([slide_type for name, slide_type in zip(slide_names, slide_types) if row['PatientID'] in name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['slide_paths'] = df['slide_paths'].str.split(',')\n",
    "df['slide_types'] = df['slide_types'].str.split(',')\n",
    "\n",
    "# Verify that the lists in 'a' and 'b' have the same length, this is crucial\n",
    "assert all(df['slide_paths'].str.len() == df['slide_types'].str.len()), \"Lists in 'slide_paths' and 'b' have different lengths.\"\n",
    "\n",
    "# Explode 'a' and 'b' simultaneously by combining them into a list of tuples\n",
    "df['combined'] = df.apply(lambda x: list(zip(x['slide_paths'], x['slide_types'])), axis=1)\n",
    "\n",
    "# Now explode the 'combined' column\n",
    "df_exploded = df.explode('combined')\n",
    "\n",
    "# Split the 'combined' tuples into separate columns\n",
    "df_exploded[['slide_paths', 'slide_types']] = pd.DataFrame(df_exploded['combined'].tolist(), index=df_exploded.index)\n",
    "\n",
    "# Drop the 'combined' column as it's no longer needed\n",
    "df_exploded = df_exploded.drop('combined', axis=1)\n",
    "\n",
    "# Rename columns for CLAM compatability.\n",
    "df_exploded = df_exploded.rename(columns={\"PatientID\":\"case_id\",\"slide_paths\":\"slide_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scale all genmoic features.\n",
    "scaler = StandardScaler()\n",
    "genomic_features = [\"Signature.1\",\"Signature.2\",\"Signature.3\",\"Signature.5\",\"Signature.8\",\"Signature.13\",\"Microhomology2\",\"Microhomology2ratio\",\"Del/ins-ratio\",\"Del10-ratio\",\"HRD-LOH\",\"Telomeric.AI\",\"LST\",\"DBS2\",\"DBS4\",\"DBS5\",\"DBS6\",\"DBS9\",\"SBS1\",\"SBS2\",\"SBS3\",\"SBS5\",\"SBS8\",\"SBS13\",\"SBS18\",\"SBS26\",\"SBS35\",\"SBS38\",\"SBS39\",\"SBS40\",\"SBS41\",\"ID1\",\"ID2\",\"ID4\",\"ID8\",\"HRDetect\"]\n",
    "# log transform.  \n",
    "# Log Transformation (adding a small value to avoid log(0))\n",
    "df_exploded[genomic_features] = df_exploded[genomic_features].applymap(lambda x: np.log(x + 1))\n",
    "# Standard Scaling\n",
    "genomic_features_scaled = scaler.fit_transform(df_exploded[genomic_features])\n",
    "df_exploded[genomic_features] = genomic_features_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded.to_csv(\"/mnt/ncshare/ozkilim/BRCA/data/tasks/combined_genomic_plat_responce.csv\",index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
